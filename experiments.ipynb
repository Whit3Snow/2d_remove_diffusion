{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nas4_user/sungwonhwang/anaconda3/envs/cu113_torch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'hf_hub_download' from 'huggingface_hub' (/home/nas4_user/sungwonhwang/anaconda3/envs/cu113_torch/lib/python3.7/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_127529/3233483868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PYTORCH_CUDA_ALLOC_CONF\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"max_split_size_mb:128\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfree_guidance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStableDiffusionFreeGuidancePipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nas4_user/sungwonhwang/ws_student/hyojinjang/2D/Free-Guidance-Diffusion/free_guidance.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLMSDiscreteScheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUNet2DConditionModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoencoderKL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDDPMScheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDDIMScheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDPMSolverMultistepScheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStableDiffusionPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIPTextModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIPImageProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m from diffusers.pipelines.stable_diffusion import (\n",
      "\u001b[0;32m/home/nas4_user/sungwonhwang/anaconda3/envs/cu113_torch/lib/python3.7/site-packages/diffusers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.18.2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m from .utils import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nas4_user/sungwonhwang/anaconda3/envs/cu113_torch/lib/python3.7/site-packages/diffusers/configuration_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhf_hub_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRevisionNotFoundError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'hf_hub_download' from 'huggingface_hub' (/home/nas4_user/sungwonhwang/anaconda3/envs/cu113_torch/lib/python3.7/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "import torch\n",
    "from free_guidance import StableDiffusionFreeGuidancePipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn import init\n",
    "from utils.guidance_functions import *\n",
    "import argparse\n",
    "from diffusers import LMSDiscreteScheduler, DDPMScheduler, DDIMScheduler, DPMSolverMultistepScheduler\n",
    "from utils import *\n",
    "from PIL import Image\n",
    "torch.cuda.manual_seed_all(1234) \n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "mpl.rcParams['image.cmap'] = 'gray_r'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Start Inference!\")\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--model_id', type=str, default=\"/data/zsz/models/storage_file/models/models--runwayml--stable-diffusion-v1-5/snapshots/1d0c4ebf6ff58a5caecab40fa1406526bca4b5b9\")\n",
    "# parser.add_argument('--seed', type=int, default=None)\n",
    "# args = parser.parse_args()\n",
    "# ded79e214aa69e42c24d3f5ac14b76d568679cc2\n",
    "model_id = \"/data/zsz/models/storage_file/models/models--runwayml--stable-diffusion-v1-5/snapshots/1d0c4ebf6ff58a5caecab40fa1406526bca4b5b9\"\n",
    "# model_id = \"/data/zsz/models/storage_file/models/models--stabilityai--stable-diffusion-2-1/snapshots/5cae40e6a2745ae2b01ad92ae5043f95f23644d6\"\n",
    "device = \"cuda\"\n",
    "pipe = StableDiffusionFreeGuidancePipeline.from_pretrained(model_id, torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.unet = UNetDistributedDataParallel(pipe.unet, device_ids=[0]).cuda()\n",
    "# pipe.vae = UNetDistributedDataParallel(pipe.vae, device_ids=[0,1,2]).cuda()\n",
    "# pipe.text_encoder = UNetDistributedDataParallel(pipe.text_encoder, device_ids=[0,1,2]).cuda()\n",
    "# pipe.unet = pipe.unet.to(device)\n",
    "# pipe.text_encoder = UNetDistributedDataParallel(pipe.text_encoder, device_ids=[0,1,2,3,4], output_device=3).cuda()\n",
    "# pipe.unet.config, pipe.unet.dtype, pipe.unet.attn_processors, pipe.unet.set_attn_processor = pipe.unet.module.config, pipe.unet.module.dtype, pipe.unet.module.attn_processors, pipe.unet.module.set_attn_processor\n",
    "# pipe.unet.config, pipe.unet.dtype = pipe.unet.module.config, pipe.unet.module.dtype\n",
    "pipe.unet = pipe.unet.module\n",
    "pipe = pipe.to(device)\n",
    "pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_attention_slicing()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Eq(10)\n",
    "seed = int(torch.rand((1,)) * 1000000)\n",
    "# 642001\n",
    "generator=torch.manual_seed(642001)\n",
    "print(seed)\n",
    "image_list = pipe(prompt=\"a photo of a bird drinking coffee at a diner\", height=512, width=512, num_inference_steps=35, generator=generator,\n",
    "        max_guidance_iter_per_step=2, guidance_func=edit_appearance, g_weight=7500)\n",
    "ls = ['edit', 'ori']\n",
    "for i, image in enumerate(image_list):\n",
    "    image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "# 97243\n",
    "print(seed)\n",
    "guidance = partial(edit_appearance, shape_weight=1.5)\n",
    "image_list = pipe(prompt=\"a photo of a boombox on a camel near a pond\", height=512, width=512, num_inference_steps=35, generator=generator,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=2000)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "objects = ['a bear', 'birthday cake', 'a fridge']\n",
    "print(seed)\n",
    "# 80836\n",
    "prompt=\"a photo of a bear eating his birthday cake near a fridge\"\n",
    "guidance = partial(edit_appearance, shape_weight=1.5)\n",
    "image_list = pipe(prompt, objects=objects, height=512, width=512, num_inference_steps=35, generator=generator,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=2000)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "objects = ['a bear', 'a suit', 'birthday cake', 'a fridge']\n",
    "print(seed)\n",
    "# 78385\n",
    "prompt=\"a photo of a bear wearing a suit eating his birthday cake near a fridge\"\n",
    "guidance = partial(edit_appearance, shape_weight=1.5)\n",
    "image_list = pipe(prompt, objects=objects, height=512, width=512, num_inference_steps=35, generator=generator,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=1000)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "print(seed)\n",
    "prompt = '“a top-down photo of a tea kettle, a bowl of fruit, and a cup of mocha'\n",
    "objects = ['kettle', 'fruit', 'matcha']\n",
    "guidance = partial(edit_appearance, shape_weight=2)\n",
    "image_list = pipe(prompt, objects=objects, height=512, width=512, num_inference_steps=35, generator=generator,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=1500)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Eq(13)\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "print(seed)\n",
    "prompt = 'a photo of a donut on a grassy field'\n",
    "ori_prompt='a photo of a donut'\n",
    "objects = ['a donut']\n",
    "guidance = partial(edit_layout, appearance_weight=2)\n",
    "feature_layer = pipe.unet.up_blocks[-1].resnets[-2]\n",
    "image_list = pipe(prompt, ori_prompt, objects=objects, height=512, width=512, num_inference_steps=35, generator=generator,\n",
    "        max_guidance_iter_per_step=5, guidance_func=guidance, g_weight=1500, feature_layer=feature_layer)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_attention dimension\n",
    "down_blocks：\n",
    "4096 4096\n",
    "1024 1024\n",
    "256 256\n",
    "mid：\n",
    "64\n",
    "up_block：\n",
    "256 256 256\n",
    "1024 1024 1024\n",
    "4096 4096 4096\n",
    "res activation\n",
    "down_blocks：\n",
    "layer1 (1,320,64,64)\n",
    "layer2 (1,640,32,32)\n",
    "layer3 (1,1280,16,16)\n",
    "layer4 (1,1280,8,8)\n",
    "up_block：\n",
    "layer1 (1,1280,8,8)\n",
    "layer2 (1,1280,16,16)\n",
    "layer3 (1,640,32,32)\n",
    "layer4 (1,320,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Eq(13)\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "print(seed)\n",
    "prompt = 'a photo of a donut on a grassy field'\n",
    "# ori_prompt='a photo of a donut'\n",
    "objects = ['a donut']\n",
    "guidance = partial(edit_layout, appearance_weight=2)\n",
    "# 64*64\n",
    "feature_layer = pipe.unet.up_blocks[-1].resnets[-1]\n",
    "image_list = pipe(prompt, objects=objects, height=512, width=512, num_inference_steps=35, generator=generator,\n",
    "        max_guidance_iter_per_step=5, guidance_func=guidance, g_weight=3500, feature_layer=feature_layer)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Eq(13)\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "print(seed)\n",
    "prompt = 'a photo of a donut falling on a swimming pool'\n",
    "ori_prompt='a photo of a donut'\n",
    "objects = ['a donut']\n",
    "guidance = partial(edit_layout, appearance_weight=3)\n",
    "# 32*32\n",
    "feature_layer = pipe.unet.up_blocks[-2].resnets[-2]\n",
    "image_list = pipe(prompt, ori_prompt, objects=objects, height=512, width=512, num_inference_steps=35, generator=generator,\n",
    "        max_guidance_iter_per_step=5, guidance_func=guidance, g_weight=4500, feature_layer=feature_layer)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Eq(13)\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "# seed = 52158\n",
    "generator=torch.manual_seed(seed)\n",
    "print(seed)\n",
    "prompt = 'a photo of an oak tree on a grass field'\n",
    "objects = ['an oak tree', 'a grass field']\n",
    "guidance = partial(edit_layout, appearance_weight=1.5)\n",
    "feature_layer = pipe.unet.up_blocks[-1].resnets[-2]\n",
    "img_path = './img/tree.png'\n",
    "init_latents = get_latents_from_image(pipe, img_path, device)\n",
    "image_list = pipe(prompt, ori_prompt=None, objects=objects, height=512, width=512, num_inference_steps=35, \n",
    "                  generator=generator, latents=init_latents,\n",
    "        max_guidance_iter_per_step=3, guidance_func=guidance, g_weight=7500, feature_layer=feature_layer)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], Image.open(img_path)]], titles=['edited', 'original'], save_orig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(44161)\n",
    "# 44161\n",
    "print(seed)\n",
    "prompt = 'a photo of a chicken walking across the street with an Italian sports car waiting for it'\n",
    "ori_prompt='a photo of a chicken'\n",
    "objects = ['chicken', 'street','Italian sports car']\n",
    "guidance = partial(edit_layout, appearance_weight=2)\n",
    "# 32*32\n",
    "feature_layer = pipe.unet.up_blocks[-1].resnets[-2]\n",
    "image_list = pipe(prompt, ori_prompt, objects=objects, height=512, width=512, num_inference_steps=35, generator=generator,\n",
    "        max_guidance_iter_per_step=4, guidance_func=guidance, g_weight=7500, feature_layer=feature_layer)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'], save_orig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(44161)\n",
    "# 44161\n",
    "print(seed)\n",
    "prompt = 'a photo of a chicken walking across the street with an Italian sports car waiting for it'\n",
    "ori_prompt='a photo of a chicken'\n",
    "objects = ['chicken', 'street','Italian sports car']\n",
    "guidance = partial(edit_layout, appearance_weight=2)\n",
    "# 32*32\n",
    "feature_layer = pipe.unet.up_blocks[-1].resnets[-2]\n",
    "img_path = './img/chicken.png'\n",
    "init_latents = get_latents_from_image(pipe, img_path, device)\n",
    "image_list = pipe(prompt, ori_prompt=ori_prompt, objects=objects, height=512, width=512, \n",
    "                  num_inference_steps=35, generator=generator, latents = init_latents,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=7500, feature_layer=feature_layer)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], Image.open(img_path)]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Eq(13)\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "print(seed)\n",
    "prompt = 'a photo of an owl and a pig running at the racetrack'\n",
    "ori_prompt='a photo of an owl and a pig'\n",
    "objects = ['an owl', 'a pig']\n",
    "guidance = partial(edit_layout, appearance_weight=2)\n",
    "# 32*32\n",
    "feature_layer = pipe.unet.up_blocks[-1].resnets[-1]\n",
    "image_list = pipe(prompt, ori_prompt, objects=objects, height=512, width=512, num_inference_steps=50, generator=generator,\n",
    "        max_guidance_iter_per_step=4, guidance_func=guidance, g_weight=1500, feature_layer=feature_layer)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(21533)\n",
    "print(seed)\n",
    "prompt = 'a red balloon floating in the air'\n",
    "object_to_edit = 'red balloon'\n",
    "move = partial(roll_shape, direction='left', factor=0.4)\n",
    "guidance = partial(move_object_by_shape, shape_weight=1, appearance_weight=1, position_weight=6, tau=move)\n",
    "image_list = pipe(prompt, obj_to_edit =object_to_edit, height=512, width=512, num_inference_steps=50, generator=generator,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=1500)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(56572)\n",
    "print(seed)\n",
    "prompt = 'a red balloon floating in the air'\n",
    "object_to_edit = 'red balloon'\n",
    "move = partial(roll_shape, direction='down', factor=0.5)\n",
    "guidance = partial(move_object_by_shape, shape_weight=1, appearance_weight=1, position_weight=7, tau=move)\n",
    "image_list = pipe(prompt, obj_to_edit =object_to_edit, height=512, width=512, num_inference_steps=50, generator=generator,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=2500)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(77944)\n",
    "print(seed)\n",
    "prompt = 'a photo of an donut and a shot of espresso on a table'\n",
    "object_to_edit = 'donut'\n",
    "objects = ['donut', 'espresso']\n",
    "move = partial(roll_shape, direction='left', factor=0.3)\n",
    "guidance = partial(move_object_by_shape, shape_weight=1, appearance_weight=2, position_weight=6, tau=move)\n",
    "img_path = './img/donut.png'\n",
    "init_latents = get_latents_from_image(pipe, img_path, device)\n",
    "image_list = pipe(prompt, obj_to_edit = object_to_edit, height=512, width=512, \n",
    "                  num_inference_steps=50, generator=generator, \n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=2500)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'], save_orig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(88969)\n",
    "print(seed)\n",
    "prompt = 'a photo of a donut and a shot of espresso on a table'\n",
    "object_to_edit = 'donut'\n",
    "objects = ['donut', 'espresso']\n",
    "move = partial(roll_shape, direction='up', factor=0.4)\n",
    "guidance = partial(move_object_by_shape, shape_weight=0.5, appearance_weight=0.5, position_weight=6, tau=move)\n",
    "img_path = './img/donut.png'\n",
    "init_latents = get_latents_from_image(pipe, img_path, device)\n",
    "image_list = pipe(prompt, obj_to_edit = object_to_edit, height=512, width=512, \n",
    "                  num_inference_steps=50, generator=generator, latents=init_latents,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=1500)\n",
    "# ls = ['edit', 'ori']\n",
    "# for i, image in enumerate(image_list):\n",
    "#     image.images[0].save(f\"results/{seed}_{ls[i]}.png\")\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'], save_orig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "print(seed)\n",
    "prompt = 'a photo of a donut and a shot of coffee on a table'\n",
    "object_to_edit = 'donut'\n",
    "objects = ['donut', 'coffee']\n",
    "resize = partial(resize, scale_factor=0.5)\n",
    "guidance = partial(resize_object_by_shape, shape_weight=0.5, appearance_weight=0.5, size_weight=8, tau=resize)\n",
    "img_path = './img/coffee.png'\n",
    "init_latents = get_latents_from_image(pipe, img_path, device)\n",
    "image_list = pipe(prompt, obj_to_edit = object_to_edit, height=512, width=512,\n",
    "                  num_inference_steps=50, generator=generator, objects = objects, latents=init_latents,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=500)\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nerf_hj' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n nerf_hj ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = int(torch.rand((1,)) * 100000)\n",
    "generator=torch.manual_seed(seed)\n",
    "print(seed)\n",
    "prompt = 'a photo of a donut'\n",
    "object_to_edit = 'donut'\n",
    "# objects = ['donut', 'coffee']\n",
    "resize = partial(resize, scale_factor=2)\n",
    "guidance = partial(resize_object_by_shape, shape_weight=0.5, appearance_weight=0.5, size_weight=10, tau=resize)\n",
    "# img_path = 'coffee.png'\n",
    "# init_latents = get_latents_from_image(pipe, img_path, device)\n",
    "image_list = pipe(prompt, obj_to_edit = object_to_edit, height=512, width=512,\n",
    "                  num_inference_steps=50, generator=generator,\n",
    "        max_guidance_iter_per_step=1, guidance_func=guidance, g_weight=500)\n",
    "show_images([i for i in [image_list[0].images[0], image_list[1].images[0]]], titles=['edited', 'original'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVPR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
